---
title: "IU Fingerprinting Vignette"
author: "Lily Koffman"
date: "2023-02-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
library(tidyverse) 
library(purrr)
library(broom)
library(ggplot2)
library(gt)
library(viridis)
library(gridExtra)
options(dplyr.summarise.inform = FALSE)
`%notin%` <- Negate(`%in%`)
theme_set(theme_minimal())
get_density <- function(x, y, ...) {
      dens <- MASS::kde2d(x, y, ...)
      ix <- findInterval(x, dens$x)
      iy <- findInterval(y, dens$y)
      ii <- cbind(ix, iy)
      return(dens$z[ii])
    }
```

```{r read in data}
df_all <- read.csv("df_all.csv")[,-1]
all_data <- read_csv("all_data.csv")[,-1]
```

```{r functions}


# function to transform time series into predictors for one subject 
get_grid_data  <- function(subject, time_lags, gcell_size, location, sessions, data){
  df <- data %>% filter(loc==location & session %in% sessions) # filter data to location and session of interest
  max_signal <- round(max(df$signal), 0) # get max signal for all subjects
  tmp <- df %>% filter(ID == subject) # filter to subject 
  n <- max(tmp$J) # number of total seconds for that subject 
  seconds <- rep(seq(1, n, 1), each=length(time_lags)) # vector of seconds and lags so that we can iterate over both
  lags <- rep(time_lags, n) # vector of lags 
  get_grid_data_onesubj <- function(second, lag){
    # function that gets number of points in each "grid cell" for a given second and given lag 
    tmp %>% filter(J==second) %>% dplyr::select(signal, t) %>% mutate(
      lag_signal = lag(signal, n = lag)  # for each second, calculate signal and lagged signal 
    ) %>% filter(!is.na(lag_signal)) %>% mutate(cut_sig = cut(signal, breaks = seq(0, max_signal, by = gcell_size), include.lowest = T),
                                                cut_lagsig = cut(lag_signal, breaks = seq(0, max_signal, by = gcell_size), include.lowest = T)) %>% 
      drop_na() %>% # count # points in each "grid cell" 
      count(cut_sig, cut_lagsig, .drop=FALSE) %>% mutate(lag_hz = lag, ID = subject, J = second, cell = paste(cut_sig, cut_lagsig, lag_hz)) %>%
      dplyr::select(n, ID, J, cell) 
  }
  # apply above function over all seconds and lags, return df
  map2_dfr(.x = seconds, .y = lags, 
           .f = get_grid_data_onesubj) %>% pivot_wider(id_cols = c(ID, J), names_from = cell, values_from = n) # apply across all seconds and lags 
  
}

# function to get candidate predictors - based on threshold for one subject 
get_grids <- function(subject, threshold, training_data){
  training_data %>% filter(ID==subject) %>% pivot_longer(cols = -ID) %>% 
    mutate(lag = sub("^.+] ", "", name)) %>% group_by(name, lag) %>% 
    summarize(value = sum(value)) %>% group_by(lag) %>% mutate(
      group_sum = sum(value) # calculate number of points across one lag, all seconds
    ) %>% ungroup() %>% mutate(
      pct = value/group_sum # calculate pct of observations in each cell 
    ) %>% filter(pct >= threshold) %>% dplyr::select(name)  %>% unlist() %>% unname() # filter 
}

# function to fit models with n predictors each 
fit_model <- function(subject, n_predictors, train, test, threshold){
  # first filter to grids above threshold 
  grids <- train %>% filter(ID==subject) %>% pivot_longer(cols = -ID) %>% 
    mutate(lag = sub("^.+] ", "", name)) %>% group_by(name, lag) %>% 
    summarize(value = sum(value)) %>% group_by(lag) %>% mutate(
      group_sum = sum(value)
    ) %>% ungroup() %>% mutate(
      pct = value/group_sum
    ) %>% filter(pct >= threshold) %>% dplyr::select(name)  %>% unlist() %>% unname()
  # make outcome binary 
  train$class <- ifelse(train$ID==subject, 1, 0)
  test$class <- ifelse(test$ID==subject, 1, 0)
  # with the training data, fit a logistic regression with each predictor individually and get p-value 
  # select __ lowest p values based on n_predictors input 
  imp_grids <- train %>% dplyr::select(all_of(grids)) %>%
    map(~glm(train$class ~.x, data = train, family = binomial(link="logit"))) %>%
    map(summary.glm) %>% map(c("coefficients")) %>% map_dbl(8) %>% as.data.frame() %>% rename("pval" = ".") %>% slice_min(pval, n=n_predictors) %>% rownames()
  # select important grids from train and test data 
  tmp <- train %>% dplyr::select(c(class, all_of(imp_grids))) 
  tmp_test <- test %>% dplyr::select(all_of(imp_grids))
  # fit logistic regression 
  mod <- glm(class ~ ., data = tmp, family=binomial(link="logit"))
  # extract predictors
  pred <- predict.glm(mod, newdata = tmp_test, type = "response")
  # return data frame with predictions, model, and subject 
  return(cbind(pred, rep(subject, length(pred)), test$ID) %>% data.frame() %>% rename("model" = "V2", "true_subject" = "V3"))
}

# functions to summarize and plot results 
# input: data frame of predictions from fit_model 
# output: summary of incorrect subjects (table) and prediction accuracy 
summarize_preds <- function(all_predictions){
  # group by the true subject and the model
  # for example, predictions from model k, row j is prob(row of j data is from subject k)
  # get the mean predicted probabilities and see if highest predicted prob is "correct" 
  df <- all_predictions %>% group_by(true_subject, model) %>% summarize(mean_pred = mean(pred)) %>% 
    group_by(true_subject) %>% summarize(
    maxprob = max(mean_pred),
    prediction = model[mean_pred==maxprob], # which subject has highest predicted probability 
    probsubj = mean_pred[true_subject==model] # which probability comes from the "true" model 
  ) %>% mutate(
    correct = ifelse(as.numeric(prediction)==true_subject, 1, 0)
  ) 
  df %>% filter(correct==0) %>% dplyr::select(-correct) %>% gt() %>% 
    tab_header(title = "Incorrect Subjects Summary",
               subtitle = paste("Correct prediction rate: ", round(sum(df$correct)/nrow(df), 2))) %>%
    cols_label(true_subject = "Subject",
               maxprob = "Highest Predicted Probability",
               prediction = "Predicted Subject",
               probsubj = "True Subject Predicted Probability") %>% fmt_number(columns = c(2,4), decimals=2)
}
# function to plot results 
plot_preds <- function(all_predictions, title=NULL){
  subj <- unique(all_predictions$true_subject)
  vlines <- subj
  col1 <-"firebrick3"; col2 <- "springgreen3"
  df <- all_predictions %>% group_by(true_subject, model) %>% summarize(mean_pred = mean(pred))  %>% group_by(true_subject) %>% summarize(
    maxprob = max(mean_pred),
    prediction = model[mean_pred==maxprob],
    probsubj = mean_pred[true_subject==model]
  ) %>% mutate(
    correct = ifelse(as.numeric(prediction)==true_subject, 1, 0)
  ) 
  num_wrong <- nrow(df[df$correct!=1,])
  g <-  all_predictions %>% group_by(true_subject, model) %>% summarize(mean_pred = mean(pred)) %>% mutate(
    correct = ifelse(true_subject==model, "Correct", "Incorrect"))%>% ggplot(aes(x = true_subject, y= mean_pred, col = as.factor(correct)))+theme_minimal()+
    labs(x = "Subject ID", y= "Avg. Predicted Probability", subtitle = paste(num_wrong, "Subjects Incorrect"))+ 
    scale_color_manual(name = "", values=c("Correct"=col2, "Incorrect" = col1))+
    geom_vline(xintercept=vlines, col = "lightgrey", alpha=.2)+scale_x_continuous(breaks=subj)+
    geom_jitter(size=3, alpha=.8, width = .1)+theme(legend.position="bottom")+scale_y_continuous(limits=c(0,1))
  if(is.null(title)){g}
  else{g + ggtitle(paste(title))}
}

# function to do all of the above process for session, location, training %, time lag, threshold, num preds 

pipeline <- function(data, sessions, location, training_pct, time_lags, gcell_size, threshold, n_predictors){
  # get vector of subjects 
  subjects <- data %>% filter(session %in% sessions, loc==location) %>% dplyr::select(ID) %>% distinct() %>% unlist()
# get grid data (predictors)  
  data_all <- map_dfr(subjects, get_grid_data,
    time_lags = time_lags, gcell_size = gcell_size, location=location, session=sessions, data=data)
  # get training and testing data based on pct supplied 
  data_train <- data_all %>% group_by(ID) %>% 
    mutate( maxJ = max(J)) %>% filter(J <= maxJ*training_pct) %>% dplyr::select(-c(J, maxJ)) %>% ungroup()
  data_test <- data_all %>% group_by(ID) %>% 
    mutate( maxJ = max(J)) %>% filter(J > maxJ*training_pct) %>%  dplyr::select(-c(J, maxJ)) %>% ungroup()
  # fit models 
  all_predictions <- map_dfr(.x = subjects, n_predictors=n_predictors, train = data_train,
                             test = data_test,threshold = threshold,
                             .f = fit_model)
  # print summary 
  summarize_preds(all_predictions = all_predictions)
  # store plot 
  g <- plot_preds(all_predictions = all_predictions)
  # save predictions 
  return(list(predictions = all_predictions, plot = g, data = data_all))
}

get_roc <- function(all_predictions, individual = F){
  test_preds_wide <- all_predictions %>% group_by(model) %>% dplyr::select(-true_subject) %>% group_split() %>% bind_cols() %>% dplyr::select(-starts_with("model"))
  colnames(test_preds_wide) <- unique(all_predictions$true_subject) # rename columns to match models 
  true <- all_predictions$true_subject[1:nrow(test_preds_wide)] # get true subjects 
  multiroc <- pROC::multiclass.roc(true, as.matrix(test_preds_wide))
  if(individual == F){
    return(round(multiroc$auc, 2))
    print(round(multiroc$auc, 2))
  }
  else{
    split_df <- all_predictions %>%  mutate(class =ifelse(model==true_subject, 1, 0)) %>% group_by(model) %>% 
      group_split()
    roc_objects <- map(.x = split_df, response = class, predictor = pred, .f = pROC::roc)
    g.list <- pROC::ggroc(roc_objects)
    g <- g.list+scale_color_viridis_d(name = "Subject")+labs(x = "Specificity", y = "Sensitivity", title = "AUC Curves",
                                                             subtitle = paste("Multiple AUC:", round(multiroc$auc, 2)))+theme_minimal() 
    aucs <- map_dbl(.x = roc_objects, .f = pROC::auc) 
    print(g)
    return(list(multiroc = multiroc$auc, aucs = aucs, plot = g))
  }
}




```


### Data Summary

For each subject, gait acceleration series measured simultaneously at the right wrist, left hip, right ankle, and left ankle. The data are collected at 100 Hz.

```{r data summary}
df_all %>% group_by(ID2) %>% summarize(
 seconds = max(J),
 mins = round(seconds/60, 2)) %>% gt() %>% tab_header(title= "Summary of Times by Session and Recording") %>% 
  cols_label(ID2 = "Subject", seconds = "Number Seconds", mins = "Minutes")
```

We see that we have between approximately 9 and 13 minutes of data for each individual.  

### Data Visualization

We look at the raw times series for a subject, and also the lag 15 second densities. 

```{r data vis}
# we want to visualize a few subjects

df_all %>% filter(ID2==1&J<=5) %>% dplyr::select(ID2, t, signal_lw, signal_lh, signal_ra, signal_la) %>% pivot_longer(cols = 3:6) %>%
  ggplot(aes(x = t/100, y = value, col = name))+geom_line()+labs(
  x = "Time (sec)", y = "Acceleration (g)", title = "5 Seconds of Data from Various Locations",
  subtitle= "Subject 1"
)+scale_x_continuous(breaks=seq(0, 5,1))+scale_colour_viridis_d(name = "Location", labels = c("L. Ankle", "L. Hip", "L. Wrist", "R. Ankle"))

df_all %>% filter(ID2==1&J<=5) %>% dplyr::select(ID2, t, signal_lw, signal_lh, signal_ra, signal_la) %>% pivot_longer(cols = 3:6) %>%
  ggplot(aes(x = t/100, y = value, col = name))+geom_line()+labs(
  x = "Time (sec)", y = "Acceleration (m/s^2)", title = "5 Seconds of Data from Various Locations",
  subtitle= "Subject 1"
)+scale_x_continuous(breaks=seq(0, 5,1))+facet_wrap(.~name)+scale_color_viridis_d()+theme(legend.position="none")


df_all %>% filter((ID2==1|ID2==2)&J<=5) %>% dplyr::select(ID2, t, signal_lw) %>%
  ggplot(aes(x = t/100, y = signal_lw, col = factor(ID2)))+geom_line()+labs(
  x = "Time (sec)", y = "Acceleration (m/s^2)", title = "5 Seconds of Data", subtitle = "Left Wrist")+scale_x_continuous(breaks=seq(0, 5,1))+scale_color_viridis_d(name = "Subject")


```
```{r plot densities }
dens <- df_all %>% filter(ID2==1) %>% dplyr::select(signal_lw, t) %>% mutate(
      lag_signal = lag(signal_lw, n = 15)  # for each second, calculate signal and lagged signal 
    ) %>% filter(!is.na(lag_signal))
dens$density <- get_density(dens$signal_lw, dens$lag_signal, n = 100)

lw <- ggplot(dens, aes(x = signal_lw, y  = lag_signal, color = density))+geom_point()+scale_color_viridis(name = "Density")+
  labs( x = "Signal (m/s2)", y = "Lag Signal (m/s2)", title = "Densities Subject 1, Left Wrist, Lag = 0.15s")

dens <- df_all %>% filter(ID2==1) %>% dplyr::select(signal_la, t) %>% mutate(
      lag_signal = lag(signal_la, n = 15)  # for each second, calculate signal and lagged signal 
    ) %>% filter(!is.na(lag_signal))
dens$density <- get_density(dens$signal_la, dens$lag_signal, n = 100)

la <- ggplot(dens, aes(x = signal_la, y  = lag_signal, color = density))+geom_point()+scale_color_viridis(name = "Density")+
  labs( x = "Signal (m/s2)", y = "Lag Signal (m/s2)", title = "Densities Subject 1, Left Ankle, Lag = 0.15s")
grid.arrange(lw, la)

# subject 2
dens <- df_all %>% filter(ID2==2) %>% dplyr::select(signal_lw, t) %>% mutate(
      lag_signal = lag(signal_lw, n = 15)  # for each second, calculate signal and lagged signal 
    ) %>% filter(!is.na(lag_signal))
dens$density <- get_density(dens$signal_lw, dens$lag_signal, n = 100)

lw <- ggplot(dens, aes(x = signal_lw, y  = lag_signal, color = density))+geom_point()+scale_color_viridis(name = "Density")+
  labs( x = "Signal (m/s2)", y = "Lag Signal (m/s2)", title = "Densities Subject 2, Left Wrist, Lag = 0.15s")

dens <- df_all %>% filter(ID2==2) %>% dplyr::select(signal_la, t) %>% mutate(
      lag_signal = lag(signal_la, n = 15)  # for each second, calculate signal and lagged signal 
    ) %>% filter(!is.na(lag_signal))
dens$density <- get_density(dens$signal_la, dens$lag_signal, n = 100)

la <- ggplot(dens, aes(x = signal_la, y  = lag_signal, color = density))+geom_point()+scale_color_viridis(name = "Density")+
  labs( x = "Signal (m/s2)", y = "Lag Signal (m/s2)", title = "Densities Subject 2, Left Ankle, Lag = 0.15s")
grid.arrange(lw, la)
```

### Model Fitting 

We calculate the grid cell predictors using time lags of 0.15, 0.30, 0.45, 0.60, 0.75, and 0.90 seconds and grid cell size of 0.25 m/s2. We split the data into 75\% training and 25\% testing. We filter the training data to the grid cells with at least 0.1\% of the data; we use these grid cells as predictors in a logistic regression. We use one vs. rest logistic regression to obtain predicted probabilities for each subject on the testing data. Then we calculate the average probability for each subject and determine whether the model has identified the correct individual. Finally, we plot the predicted probabilities, calculate the overall AUC, and plot each individual AUC curve. 

```{r model fitting}
training_pct <- 0.75 
threshold <- 0.001
n_predictors=Inf

data_train <- all_data %>% group_by(ID) %>% 
  mutate( maxJ = max(J)) %>% filter(J <= maxJ*training_pct) %>% dplyr::select(-c(J, maxJ)) %>% ungroup()
data_test <- all_data %>% group_by(ID) %>% 
  mutate( maxJ = max(J)) %>% filter(J > maxJ*training_pct) %>%  dplyr::select(-c(J, maxJ)) %>% ungroup()
subjects <- unique(all_data$ID)
all_predictions <- map_dfr(.x = subjects, n_predictors=n_predictors, train = data_train,
                           test = data_test,threshold = threshold,
                           .f = fit_model)
```

### Left Wrist Results

```{r}
summarize_preds(all_predictions)
plot_preds(all_predictions)
get_roc(all_predictions, individual=T)

```

```{r}
data_train <- all_data %>% group_by(ID) %>% 
  filter(J <= 200) %>% dplyr::select(-J) %>% ungroup()
data_test <- all_data %>% group_by(ID) %>% 
  filter(J > 200 & J <=380) %>%  dplyr::select(-J) %>% ungroup()
subjects <- unique(all_data$ID)
all_predictions_orig <- map_dfr(.x = subjects, n_predictors=n_predictors, train = data_train,
                           test = data_test,threshold = threshold,
                           .f = fit_model)
```


```{r}
summarize_preds(all_predictions_orig)
plot_preds(all_predictions_orig)
get_roc(all_predictions_orig, individual=T)
```

